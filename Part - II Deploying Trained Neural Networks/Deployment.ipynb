
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "## Which files constitute a \"model\"?\n",
    "\n",
    "We make a trained network useful by removing it from its training environment and \"deploying\" it into an application. Start where we left off in DIGITS.\n",
    "\n",
    "DIGITS places the files we need to deploy in a directory that can either be downloaded or just pointed to. Since we're going to be deploying our model on the same server where it was trained, we can just point to the folder path that DIGITS generates.\n",
    "\n",
    "### <a href=\"../../../../digits\" target=\\\"_blank\\\">Open DIGITS</a>.\n",
    "\n",
    "From DIGITS home page, select the model that we named \"Dogs vs. Cats\".\n",
    "\n",
    "DIGITS' \"Job Page\" for the model is what you see as soon as you create the model, when it is training, and/or if you select the model under DIGITS' \"model\" tab. The Job Directory is in the top left.\n",
    "\n",
    "![](images/ModelJobView.PNG)\n",
    "\n",
    "**Copy the job directory (highlighted above) and replace ##FIXME## in the code block below. Once you've copied the directory, execute the cell (Shift+Enter) to store it to the variable <code>MODEL_JOB_DIR</code>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe_output.log   snapshot_iter_735.caffemodel   status.pickle\r\n",
      "deploy.prototxt    snapshot_iter_735.solverstate  train_val.prototxt\r\n",
      "original.prototxt  solver.prototxt\r\n"
     ]
    }
   ],
   "source": [
    "MODEL_JOB_DIR = '/dli/data/digits/20180301-185638-e918'  ## Remember to set this to be the job directory for your model\n",
    "!ls $MODEL_JOB_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you copied and pasted well, you will see a list of all files in that directory. If the following instructions do not match what you're seeing, check the copy/paste directions.\n",
    "\n",
    "Again, our \"model\" consists of two files: the architecture and the weights. \n",
    "\n",
    "The architecture is the file called ```deploy.prototxt``` and the weights are in the most recent snapshot file ```snapshot_iter_#.caffemodel.```In this case, snapshot number 735 contains the weights learned after all 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepath to Architecture = /dli/data/digits/20180301-185638-e918/deploy.prototxt\n",
      "Filepath to weights = /dli/data/digits/20180301-185638-e918/snapshot_iter_735.caffemodel\n"
     ]
    }
   ],
   "source": [
    "ARCHITECTURE = MODEL_JOB_DIR + '/' + 'deploy.prototxt'\n",
    "WEIGHTS = MODEL_JOB_DIR + '/' + 'snapshot_iter_735.caffemodel'\n",
    "print (\"Filepath to Architecture = \" + ARCHITECTURE)\n",
    "print(\"Filepath to weights = \"+ WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make sure that the program that we're building can both read and process those files. For this basic type of deployment, we'll need to install (or include) the framework that they were written in to be able to interpret them. We'll learn to deploy to environments that don't require installing the framework later in this course. We'll also need to use the GPU to take advantage of parallel processing. Again, our model consists of hundreds of thousands of operations that can be largely accelerated through parallelization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a \"Classifier\" object called \"net\". The more common the workflow, the easier existing tools will make your project. In this case, image classification is very common, so this next code block simply takes your architecture file and weights file and a bit about the data and makes common actions easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Caffe model using the model trained in DIGITS\n",
    "net = caffe.Classifier(ARCHITECTURE, WEIGHTS,  \n",
    "                       channel_swap =(2, 1, 0), #Color images have three channels, Red, Green, and Blue.\n",
    "                       raw_scale=255) #Each pixel value is a number between 0 and 255\n",
    "                       #Each \"channel\" of our images are 256 x 256 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Classifier class includes a method called \"predict\", which takes an input of an image as defined above and generates an output of the likelihood of the image belonging to each category.\n",
    "\n",
    "\n",
    "## Creating an Expected Input: Preprocessing\n",
    "\n",
    "To start with something easy, let's attempt to correctly classify a labeled image from the dataset. We can load the image and view it by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [